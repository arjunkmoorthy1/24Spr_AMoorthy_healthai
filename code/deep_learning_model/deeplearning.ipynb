{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_image(path, img_size=256):\n",
    "    # Load dicom and convert to 256x256 RGB image\n",
    "    dicom = pydicom.dcmread(path)\n",
    "    image = dicom.pixel_array\n",
    "    image = Image.fromarray(image).convert('RGB')\n",
    "    image = image.resize((img_size, img_size))\n",
    "    return np.array(image) / 255.0\n",
    "\n",
    "    # Convert to TensorFlow tensor\n",
    "    return tf.convert_to_tensor(image, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patient_images(patient_folder, img_size=256):\n",
    "    \"\"\"\n",
    "    Process all DICOM images of a patient and return a single representative array.\n",
    "    This is a placeholder function; you need to decide how to handle multiple images.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for filename in os.listdir(patient_folder):\n",
    "        if filename.endswith('.dcm'):\n",
    "            path = os.path.join(patient_folder, filename)\n",
    "            image = load_dicom_image(path, img_size=img_size)\n",
    "            images.append(image)\n",
    "    \n",
    "    # Placeholder: simply return the first image for now\n",
    "    if images:\n",
    "        return images[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(root_dir, img_size=256, batch_size=32):\n",
    "    # Placeholder lists for images and labels\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Navigate through the root directory and process each patient's images\n",
    "    for condition in os.listdir(root_dir):\n",
    "        condition_path = os.path.join(root_dir, condition)\n",
    "        if not os.path.isdir(condition_path):\n",
    "            continue\n",
    "        \n",
    "        label = 1 if condition.lower() == 'cancer' else 0\n",
    "        \n",
    "        for patient_folder_name in os.listdir(condition_path):\n",
    "            patient_folder_path = os.path.join(condition_path, patient_folder_name)\n",
    "            if not os.path.isdir(patient_folder_path):\n",
    "                continue\n",
    "            \n",
    "            representative_image = process_patient_images(patient_folder_path, img_size=img_size)\n",
    "            if representative_image is not None:\n",
    "                all_images.append(representative_image)\n",
    "                all_labels.append(label)\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    dataset_images = tf.stack(all_images)\n",
    "    dataset_labels = tf.convert_to_tensor(all_labels, dtype=tf.float32)\n",
    "    \n",
    "    # Create a tf.data.Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dataset_images, dataset_labels))\n",
    "    dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def build_model(input_shape=(256, 256, 3)):\n",
    "    base_model = MobileNetV2(input_shape=input_shape,\n",
    "                             include_top=False,\n",
    "                             weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset('/Users/arjunmoorthy/Desktop/Research_Capstone/Image Data/CapstoneData', img_size=256, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kq/j6d8h1bx4z5cv8c9hc3hv6yw0000gn/T/ipykernel_11039/4149438536.py:6: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(input_shape=input_shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 135ms/step - accuracy: 0.5310 - loss: 0.7394\n",
      "Epoch 2/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.5315 - loss: 0.7371\n",
      "Epoch 3/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.5763 - loss: 0.6789\n",
      "Epoch 4/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.5745 - loss: 0.6757\n",
      "Epoch 5/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.5836 - loss: 0.6698\n",
      "Epoch 6/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.5844 - loss: 0.6920\n",
      "Epoch 7/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.6053 - loss: 0.6729\n",
      "Epoch 8/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.6172 - loss: 0.6486\n",
      "Epoch 9/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.6388 - loss: 0.6547\n",
      "Epoch 10/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.6142 - loss: 0.6544\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=50)  # Adjust the number of epochs as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "dicom_dir_path = '/Users/arjunmoorthy/Desktop/Research_Capstone/Image Data/CapstoneData'  # Directory where DICOM files are stored"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
